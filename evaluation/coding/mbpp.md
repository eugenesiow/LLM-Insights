# MBPP

MBPP stands for Mostly Basic Programming Problems, a benchmark dataset from the [Program Synthesis with Large Language Models](https://arxiv.org/abs/2108.07732) paper by Austin et al. from Google Research, published in Aug 2021. MBPP contains 974 programming tasks, designed to be solvable by entry-level programmers. 

MBPP EvalPlus or MBPP+ is from the paper [Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation](https://arxiv.org/abs/2305.01210) by Liu et al., published in May 2023 to Oct 2023. MBPP+ contains 35x more tests than the original MBPP.

## Links

### MBPP

* Abstract: https://arxiv.org/abs/2108.07732
* Homepage: https://github.com/google-research/google-research/tree/master/mbpp
* Dataset: https://huggingface.co/datasets/google-research-datasets/mbpp
* License: [CC-BY-4.0](https://huggingface.co/datasets/google-research-datasets/mbpp/blob/main/README.md)

### MBPP EvalPlus

* Abstract: https://arxiv.org/abs/2305.01210
* Homepage: https://github.com/evalplus/evalplus
* Dataset: https://huggingface.co/datasets/evalplus/mbppplus
* License: [Apache 2.0](https://huggingface.co/datasets/evalplus/mbppplus/blob/main/README.md)

## Implementation

Below are [configurations](https://github.com/EleutherAI/lm-evaluation-harness/blob/main/lm_eval/tasks/mbpp) from [EleutherAI's Language Model Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness).

<details>
<summary>mbpp</summary>

```yaml
task: mbpp
dataset_path: google-research-datasets/mbpp
dataset_name: full
unsafe_code: true
output_type: generate_until
test_split: test
doc_to_text: "You are an expert Python programmer, and here is your task: {{text}} Your code should pass these tests:\n\n{{test_list[0]}}\n{{test_list[1]}}\n{{test_list[2]}}\n[BEGIN]\n"
doc_to_target: "{% if is_fewshot is defined %}{{code}}\n[DONE]{% else %}{{test_list[0]}}\n{{test_list[1]}}\n{{test_list[2]}}{% endif %}"
target_delimiter: ""
metric_list:
  - metric: !function utils.pass_at_1
    aggregation: mean
    higher_is_better: true
generation_kwargs:
  until:
    - "[DONE]"
  do_sample: false
num_fewshot: 3
fewshot_config:
  sampler: first_n
  samples: !function utils.list_fewshot_samples
metadata:
  version: 1.0

```

Source: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/lm_eval/tasks/mbpp/mbpp.yaml
</details>

<details>
<summary>mbpp_plus</summary>

```yaml
include: mbpp.yaml
task: mbpp_plus
dataset_path: evalplus/mbppplus
dataset_name: null
doc_to_text: "You are an expert Python programmer, and here is your task: {{prompt if prompt is defined else text}} Your code should pass these tests:\n\n{{test_list[0]}}\n{{test_list[1]}}\n{{test_list[2]}}\n[BEGIN]\n"

```

Source: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/lm_eval/tasks/mbpp/mbpp_plus.yaml
</details>


## Citation

```
@article{austin2021program,
  title={Program synthesis with large language models},
  author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
  journal={arXiv preprint arXiv:2108.07732},
  year={2021}
}
```

```
@inproceedings{evalplus,
  title = {Is Your Code Generated by Chat{GPT} Really Correct? Rigorous Evaluation of Large Language Models for Code Generation},
  author = {Liu, Jiawei and Xia, Chunqiu Steven and Wang, Yuyao and Zhang, Lingming},
  booktitle = {Thirty-seventh Conference on Neural Information Processing Systems},
  year = {2023},
  url = {https://openreview.net/forum?id=1qvx610Cu7},
}
```

```
@inproceedings{evalperf,
  title = {Evaluating Language Models for Efficient Code Generation},
  author = {Liu, Jiawei and Xie, Songrun and Wang, Junhao and Wei, Yuxiang and Ding, Yifeng and Zhang, Lingming},
  booktitle = {First Conference on Language Modeling},
  year = {2024},
  url = {https://openreview.net/forum?id=IBCBMeAhmC},
}
```