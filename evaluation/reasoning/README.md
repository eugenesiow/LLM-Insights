# Reasoning

Evaluations that involve logical thinking, making inferences, and drawing conclusions from given information; usually harder problems require multiple steps.

- [GPQA (Graduate-Level Google-Proof Q&A Benchmark)](gpqa.md) - PhD-level knowledge multiple choice questions in science: Chemistry, Biology, Physics.
- [ARC (AI2's Reasoning Challenge)](arc.md) - Multiple-choice question-answering dataset, containing questions from science exams from grade 3 to grade 9.
- [DROP (Discrete Reasoning Over the content of Paragraphs)](drop.md) - question-answering (QA) dataset which tests comprehensive understanding of paragraphs. To answer the questions, a model must resolve multiple references in a question, map them onto a paragraph, and perform discrete operations over them (such as addition, counting, or sorting).
- [MuSR (Multistep Soft Reasoning)](musr.md) -  evaluating language models on multistep soft reasoning tasks specified in a natural language narrative.